{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSC 678 HOMEWORK 2 (Q2)\n",
    "### VAISHNAVI JAMDADE(TM39453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import loadtxt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1=\"https://www.csee.umbc.edu/courses/graduate/678/spring20/mnist_data.txt\"\n",
    "url2=\"https://www.csee.umbc.edu/courses/graduate/678/spring20/mnist_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "raw_data = urlopen(url1)\n",
    "dataset1 = loadtxt(raw_data, delimiter=\" \")\n",
    "print(dataset1.shape)\n",
    "dataset1=dataset1.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data2 = urlopen(url2)\n",
    "dataset2 = loadtxt(raw_data2, delimiter=\" \")\n",
    "dataset2=dataset2.astype(int)\n",
    "dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to prepend 1 to input data for bias term :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ones(X):\n",
    "    \n",
    "    return np.hstack((np.ones((X.shape[0], 1),dtype=int), X)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1=add_ones(dataset1)\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting training and testing data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset1,dataset2, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 785), (5000,), (5000, 785), (5000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def training(X_train, y_train):\n",
    "        \n",
    "        dotprod=np.ndarray(10,dtype=np.float32)\n",
    "        weights=np.zeros((10,X_train.shape[1]), dtype=np.float32)\n",
    "        iterations=47                           # Number of epochs\n",
    "        alpha=0.01                              # Learning Rate\n",
    "        accu=[]\n",
    "        co=[]\n",
    "        for iter in range(iterations) : \n",
    "            count=0\n",
    "            for i in range(X_train.shape[0]): # iterating through each feature vector\n",
    "                for j in range(10):     # weight vectors equivalent to 10 class labels \n",
    "                    dotprod[j] = np.dot(X_train[i],weights[j])\n",
    "        \n",
    "                ind=y_train[i]                 # true class label\n",
    "                maxi=np.argmax(dotprod,axis=None)\n",
    "                y_pred=maxi             # got predicted corresponding class label\n",
    "       \n",
    "                if(y_pred!=y_train[i]):\n",
    "                #subtracting x input from old weight vector coress to predicted label \n",
    "                    weights[maxi] -= alpha*X_train[i]\n",
    "                  \n",
    "                #adding x input to old weight vector coress to true label \n",
    "                    weights[ind] += alpha*X_train[i]\n",
    "                    \n",
    "                elif(y_pred==y_train[i]):\n",
    "                    count=count+1\n",
    "                    \n",
    "            accuracy = round(((count/y_train.shape[0])*100), 2)\n",
    "            #print(\"Accuracy after epoch \"+ str(iter)  + \" is : \",accuracy)\n",
    "            accu.append(accuracy)\n",
    "            #print(\"Count of correctly classified samples is : \" , count)\n",
    "            co.append(count)\n",
    "            \n",
    "        zippedList =  list(zip(accu,co))\n",
    "        df=pd.DataFrame(zippedList, columns = ['Accuracy in %', 'Correctly_classified_samples'],index=None)\n",
    "        print(df)\n",
    " \n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Function : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def testing(X_test,w):\n",
    "        \n",
    "        ypred=[]\n",
    "        activ=[]\n",
    "        activ=np.dot(X_test,w.T)     #calculating activation\n",
    "        \n",
    "        for i in range(activ.shape[0]):\n",
    "            ypred.append(np.argmax(activ[i]))\n",
    "\n",
    "        return ypred           #predicted class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Accuracy in %  Correctly_classified_samples\n",
      "0           77.78                          3889\n",
      "1           85.62                          4281\n",
      "2           87.40                          4370\n",
      "3           87.84                          4392\n",
      "4           89.48                          4474\n",
      "5           89.82                          4491\n",
      "6           90.42                          4521\n",
      "7           90.54                          4527\n",
      "8           91.64                          4582\n",
      "9           91.90                          4595\n",
      "10          92.04                          4602\n",
      "11          92.76                          4638\n",
      "12          92.86                          4643\n",
      "13          93.34                          4667\n",
      "14          92.92                          4646\n",
      "15          93.06                          4653\n",
      "16          93.56                          4678\n",
      "17          94.40                          4720\n",
      "18          94.16                          4708\n",
      "19          93.90                          4695\n",
      "20          94.16                          4708\n",
      "21          94.80                          4740\n",
      "22          94.78                          4739\n",
      "23          95.32                          4766\n",
      "24          94.90                          4745\n",
      "25          95.40                          4770\n",
      "26          95.36                          4768\n",
      "27          95.74                          4787\n",
      "28          95.80                          4790\n",
      "29          95.58                          4779\n",
      "30          95.80                          4790\n",
      "31          96.18                          4809\n",
      "32          96.18                          4809\n",
      "33          96.58                          4829\n",
      "34          95.82                          4791\n",
      "35          96.54                          4827\n",
      "36          96.38                          4819\n",
      "37          95.88                          4794\n",
      "38          96.52                          4826\n",
      "39          96.56                          4828\n",
      "40          97.08                          4854\n",
      "41          96.60                          4830\n",
      "42          96.76                          4838\n",
      "43          96.42                          4821\n",
      "44          97.08                          4854\n",
      "45          97.10                          4855\n",
      "46          97.28                          4864\n"
     ]
    }
   ],
   "source": [
    " w=training(X_train, y_train)  #got updated weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation for Training DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_Training=testing(X_train,w)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples correctly classified for training data :  4902\n",
      "Accuracy in % : 98.04\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(y_train.shape[0]):\n",
    "    if predictions_for_Training[i]==y_train[i]:\n",
    "        count=count+1\n",
    "print(\"Number of samples correctly classified for training data : \", count)\n",
    "print('Accuracy in % :', accuracy_score(y_train,predictions_for_Training)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Calculation for Testing DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_Testing=testing(X_test,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples correctly classified for testing data :  4431\n",
      "Accuracy in % : 88.62\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(y_test.shape[0]):\n",
    "    if predictions_for_Testing[i]==y_test[i]:\n",
    "        count=count+1\n",
    "\n",
    "print(\"Number of samples correctly classified for testing data : \", count)\n",
    "print('Accuracy in % :', accuracy_score(y_test,predictions_for_Testing)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Explanation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here I have implemented a single layer, Multi-class perceptron. I have prepended a column of 1's to the input data for simplification in case of bias term. Further, data has been split 50-50% of training and testing data. A numpy weight array of dimensions(10,785) where (785 since 784 dimensions + bias term) has been declared.\n",
    "* In the training function, our model will learn based on our training data. With learning rate of 0.01 at each epoch, it calculates the dot product of each feature vector in input data with all the 10 weight vectors coressponding to the given 10 class labels. The index of the maximum dot product-value will be our coressponding  predicted class label.\n",
    "* If our predictions are correct, then simply store the count of correct prediction at each iteration. But if our prediction is incorrect, then the weights for the correct class are increased by x and the weights for the incorrectly predicted class are decreased by x. \n",
    "\n",
    "* Keep updating the weights for each iterations/epoch and compute the training accuracy to see variations. We will see that the accuracy has increased gradually. But after a certain epoch, we may see that accuracy tends to be almost 100% that is tends to overfit our model on training data and perform poorly on testing data.\n",
    "\n",
    "* Testing function simply takes these updated weights retrieved from training function and runs our model on test data thus returning predicted class labels. \n",
    "* Further, accuracy is calculated for test data. I have tuned my weight parameters for 47 epochs and then tested my model since after 48th epoch, it was observed that the although the training accuracy was substantially increasing, the testing accuracy began to decline noticably, that is, it was trying to overfit the model. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
